<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook For ReadMyMind, A CS 125 @ Illinois MP7 Project by Isaac Park and Mihir Pandya."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
=======
   "execution_count": 23,
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Avg. Likes</th>\n",
       "      <th>Avg. Retweets</th>\n",
       "      <th>Avg. Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america</td>\n",
       "      <td>10</td>\n",
<<<<<<< HEAD
       "      <td>77871</td>\n",
       "      <td>19453</td>\n",
=======
       "      <td>77458</td>\n",
       "      <td>19341</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.642516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>9</td>\n",
<<<<<<< HEAD
       "      <td>95661</td>\n",
       "      <td>24409</td>\n",
=======
       "      <td>94975</td>\n",
       "      <td>24229</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.601653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pensacola</td>\n",
       "      <td>8</td>\n",
<<<<<<< HEAD
       "      <td>60784</td>\n",
       "      <td>13173</td>\n",
=======
       "      <td>60672</td>\n",
       "      <td>13147</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.348522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cnn</td>\n",
       "      <td>7</td>\n",
<<<<<<< HEAD
       "      <td>113715</td>\n",
       "      <td>29318</td>\n",
=======
       "      <td>113416</td>\n",
       "      <td>29240</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.537169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>florida</td>\n",
       "      <td>6</td>\n",
<<<<<<< HEAD
       "      <td>68073</td>\n",
       "      <td>15662</td>\n",
=======
       "      <td>67995</td>\n",
       "      <td>15641</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.390126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>market</td>\n",
       "      <td>6</td>\n",
<<<<<<< HEAD
       "      <td>98315</td>\n",
       "      <td>21845</td>\n",
=======
       "      <td>98009</td>\n",
       "      <td>21773</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.527245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>economy</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>62120</td>\n",
       "      <td>14806</td>\n",
=======
       "      <td>61665</td>\n",
       "      <td>14697</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.294523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>whitehouse</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>48803</td>\n",
       "      <td>11077</td>\n",
=======
       "      <td>48774</td>\n",
       "      <td>11074</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.440833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>alabama</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>86608</td>\n",
       "      <td>22229</td>\n",
=======
       "      <td>86566</td>\n",
       "      <td>22218</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.615575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>cuts</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>94950</td>\n",
=======
       "      <td>94949</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>21501</td>\n",
       "      <td>0.616493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abc</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>110848</td>\n",
       "      <td>31529</td>\n",
=======
       "      <td>110789</td>\n",
       "      <td>31512</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.523785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Country</td>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>102850</td>\n",
       "      <td>27437</td>\n",
=======
       "      <td>102809</td>\n",
       "      <td>27427</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.542882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>join</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>45284</td>\n",
       "      <td>10909</td>\n",
=======
       "      <td>45257</td>\n",
       "      <td>10905</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>confidence</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>91449</td>\n",
       "      <td>17769</td>\n",
=======
       "      <td>91448</td>\n",
       "      <td>17770</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.523897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>maga</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>46792</td>\n",
       "      <td>9291</td>\n",
=======
       "      <td>46752</td>\n",
       "      <td>9284</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>comey</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>103160</td>\n",
=======
       "      <td>103153</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>25239</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thank</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>83659</td>\n",
       "      <td>18826</td>\n",
=======
       "      <td>83606</td>\n",
       "      <td>18815</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>christmas</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>93258</td>\n",
       "      <td>25962</td>\n",
=======
       "      <td>93254</td>\n",
       "      <td>25960</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.623016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>history</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>80627</td>\n",
       "      <td>18772</td>\n",
=======
       "      <td>80525</td>\n",
       "      <td>18748</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.493750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>korea</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>93319</td>\n",
=======
       "      <td>93320</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>19533</td>\n",
       "      <td>0.480093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>democrat</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>64191</td>\n",
       "      <td>15823</td>\n",
=======
       "      <td>64115</td>\n",
       "      <td>15800</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.650926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>jones</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>69548</td>\n",
       "      <td>17569</td>\n",
=======
       "      <td>69446</td>\n",
       "      <td>17539</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.529630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>flynn</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>118185</td>\n",
=======
       "      <td>118179</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>32841</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mississippi</td>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>57745</td>\n",
       "      <td>12527</td>\n",
=======
       "      <td>57526</td>\n",
       "      <td>12476</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.588005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>bahrain</td>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>47319</td>\n",
=======
       "      <td>47316</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>10511</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>foxnews</td>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>56152</td>\n",
       "      <td>15349</td>\n",
=======
       "      <td>56127</td>\n",
       "      <td>15343</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>crown</td>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>47319</td>\n",
=======
       "      <td>47316</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>10511</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>heroes</td>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>70365</td>\n",
       "      <td>17389</td>\n",
=======
       "      <td>70329</td>\n",
       "      <td>17385</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.631250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>senorrinhatch</td>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>62046</td>\n",
       "      <td>15877</td>\n",
=======
       "      <td>62043</td>\n",
       "      <td>15876</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.721429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pearl</td>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>79788</td>\n",
       "      <td>16842</td>\n",
=======
       "      <td>79751</td>\n",
       "      <td>16836</td>\n",
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keywords  Frequency  Avg. Likes  Avg. Retweets  Avg. Sentiment\n",
<<<<<<< HEAD
       "2          america         10       77871          19453        0.642516\n",
       "0             fake          9       95661          24409        0.601653\n",
       "11       pensacola          8       60784          13173        0.348522\n",
       "26             cnn          7      113715          29318        0.537169\n",
       "36         florida          6       68073          15662        0.390126\n",
       "3           market          6       98315          21845        0.527245\n",
       "5          economy          4       62120          14806        0.294523\n",
       "56      whitehouse          4       48803          11077        0.440833\n",
       "32         alabama          4       86608          22229        0.615575\n",
       "79            cuts          4       94950          21501        0.616493\n",
       "28             abc          4      110848          31529        0.523785\n",
       "35         Country          4      102850          27437        0.542882\n",
       "43            join          3       45284          10909        0.300000\n",
       "112     confidence          3       91449          17769        0.523897\n",
       "45            maga          3       46792           9291        0.100000\n",
       "85           comey          3      103160          25239        0.666667\n",
       "38           thank          3       83659          18826        0.710714\n",
       "98       christmas          3       93258          25962        0.623016\n",
       "24         history          3       80627          18772        0.493750\n",
       "115          korea          3       93319          19533        0.480093\n",
       "30        democrat          3       64191          15823        0.650926\n",
       "31           jones          3       69548          17569        0.529630\n",
       "89           flynn          3      118185          32841        0.533333\n",
       "23     mississippi          3       57745          12527        0.588005\n",
       "109        bahrain          2       47319          10511        0.583333\n",
       "44         foxnews          2       56152          15349        0.425000\n",
       "108          crown          2       47319          10511        0.583333\n",
       "60          heroes          2       70365          17389        0.631250\n",
       "97   senorrinhatch          2       62046          15877        0.721429\n",
       "62           pearl          2       79788          16842        0.250000"
      ]
     },
     "execution_count": 54,
=======
       "2          america         10       77458          19341        0.642516\n",
       "0             fake          9       94975          24229        0.601653\n",
       "11       pensacola          8       60672          13147        0.348522\n",
       "26             cnn          7      113416          29240        0.537169\n",
       "36         florida          6       67995          15641        0.390126\n",
       "3           market          6       98009          21773        0.527245\n",
       "5          economy          4       61665          14697        0.294523\n",
       "56      whitehouse          4       48774          11074        0.440833\n",
       "32         alabama          4       86566          22218        0.615575\n",
       "79            cuts          4       94949          21501        0.616493\n",
       "28             abc          4      110789          31512        0.523785\n",
       "35         Country          4      102809          27427        0.542882\n",
       "43            join          3       45257          10905        0.300000\n",
       "112     confidence          3       91448          17770        0.523897\n",
       "45            maga          3       46752           9284        0.100000\n",
       "85           comey          3      103153          25239        0.666667\n",
       "38           thank          3       83606          18815        0.710714\n",
       "98       christmas          3       93254          25960        0.623016\n",
       "24         history          3       80525          18748        0.493750\n",
       "115          korea          3       93320          19533        0.480093\n",
       "30        democrat          3       64115          15800        0.650926\n",
       "31           jones          3       69446          17539        0.529630\n",
       "89           flynn          3      118179          32841        0.533333\n",
       "23     mississippi          3       57526          12476        0.588005\n",
       "109        bahrain          2       47316          10511        0.583333\n",
       "44         foxnews          2       56127          15343        0.425000\n",
       "108          crown          2       47316          10511        0.583333\n",
       "60          heroes          2       70329          17385        0.631250\n",
       "97   senorrinhatch          2       62043          15876        0.721429\n",
       "62           pearl          2       79751          16836        0.250000"
      ]
     },
     "execution_count": 23,
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "\n",
=======
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
    "username = 'realDonaldTrump' # working example: Donald Trump\n",
    "\n",
    "auth = tweepy.OAuthHandler('1X5fCqPl7yVvYxQjQJwkvavFD', 'NXbTDPP3HxlXOL5dWdCegEP09odLAkxUWlyRvZqXxtAtdX597G')\n",
    "auth.set_access_token('925495606931546112-mn3Hda41LsZhbYAKJtddL7TulRKucuj', 'lvCFqSLv5YvOGzCINH6JZ5cBI1CEkPKrRioBn5Iuec3Tt')\n",
    "api = tweepy.API(auth)\n",
    "    \n",
    "tweets_df = pd.DataFrame({\n",
    "    'Timestamp': (),\n",
    "    'Likes': (),\n",
    "    'Retweets': (),\n",
    "    'Text': (),\n",
    "    'Sentences': (),\n",
    "    'Sentiment_Total': (),\n",
    "    'Keywords': ()\n",
    "})\n",
    "\n",
    "tweets_df = tweets_df[['Timestamp', 'Likes', 'Retweets', 'Text', 'Sentences', 'Sentiment_Total', 'Keywords']]\n",
    "    \n",
    "recent_tweets = api.user_timeline(screen_name = username, count=100, tweet_mode=\"extended\") # analyzing 100 tweets\n",
    "for status in recent_tweets:\n",
    "    test = status.full_text\n",
    "    if test[:2] != 'RT': # removing retweets made by the user\n",
    "        status_data = pd.Series([status.created_at, status.favorite_count, status.retweet_count, status.full_text], \n",
    "                                index=['Timestamp', 'Likes', 'Retweets', 'Text'])\n",
    "    tweets_df = tweets_df.append(status_data, ignore_index = True)\n",
    "    \n",
    "tweets_df = tweets_df.drop_duplicates(subset='Text') # just in case, remove any duplicate tweets\n",
    "tweets_df = tweets_df.astype('object')\n",
    "\n",
    "keywords_dict = {}\n",
    "\n",
    "for i in range(len(tweets_df)):\n",
    "    content = tweets_df.iloc[i]['Text']\n",
    "    if 'http' in content:\n",
    "        j = content.index('http')\n",
    "        content = content[:j] # cleaning text of the tweet by removing the link at the end and newline characters\n",
    "    content = content.replace('\\n', '')\n",
    "    tweets_df.iloc[i]['Text'] = content\n",
    "    \n",
    "    blob = TextBlob(content)\n",
    "    tweets_df.iloc[i]['Sentiment_Total'] = blob.sentiment.subjectivity\n",
    "    sentiments = {}\n",
    "    \n",
    "    for sent in blob.sentences: # generating sentiment polarity values for each sentence in the tweet\n",
    "        sentiments[str(sent)] = sent.sentiment.subjectivity\n",
    "        \n",
    "    tweets_df.iloc[i]['Sentences'] = sentiments # insert dictionary of sentence: sentiment value into dataframe\n",
    "    \n",
    "    tweets_df.iloc[i]['Timestamp'] = tweets_df.iloc[i]['Timestamp'].to_pydatetime() # convert pandas.tslib.Timestamp object to datetime\n",
    "    \n",
    "    # Keyword extraction goes here\n",
    "    filtered_words = blob.noun_phrases\n",
    "    temp = []\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for x in range(len(filtered_words)):\n",
    "            if element != filtered_words[x] and element in filtered_words[x]:\n",
    "                temp.append(element)\n",
    "    parts_of_speech = blob.tags\n",
    "    for element in temp:\n",
    "        filtered_words = [x for x in filtered_words if x != element]\n",
    "    \n",
    "    for x in range(len(parts_of_speech)):\n",
    "        if (parts_of_speech[x])[1] == 'NN':\n",
    "            enter = True\n",
    "            for element in filtered_words:\n",
    "                if (parts_of_speech[x])[0] in element:\n",
    "                    enter = False\n",
    "            if enter:\n",
    "                if x > 0 and (parts_of_speech[x - 1])[1] == 'PRP$':\n",
    "                    filtered_words.append((parts_of_speech[x])[0])\n",
    "    parenthesis = []\n",
    "    paren_init = 0\n",
    "    loc_begin = blob.find(\"(\", paren_init)\n",
    "    loc_end = blob.find(\")\", paren_init)\n",
    "    \n",
    "    while loc_end >= 0:\n",
    "        parenthesis.append(blob[loc_begin:loc_end])\n",
    "        paren_init = loc_end + 1\n",
    "        loc_begin = blob.find(\"(\", paren_init)\n",
    "        loc_end = blob.find(\")\", paren_init)\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for pelement in parenthesis:\n",
    "            if element in pelement.lower():\n",
    "                filtered_words = [x for x in filtered_words if x != element]        \n",
    "    \n",
    "    for word in filtered_words:\n",
    "        separated = TextBlob(word).words\n",
    "        for j in separated:\n",
    "            j = word.strip()\n",
    "            tb = ((TextBlob(j).tags)[0])[1]\n",
    "            if j.isalpha() and len(j) > 2 and (tb == 'NN' or tb == 'NNS' or tb == 'VBP'):\n",
    "                if j in keywords_dict:\n",
    "                    keywords_dict[j][0] += 1\n",
    "                    keywords_dict[j][1] += tweets_df.iloc[i]['Likes']\n",
    "                    keywords_dict[j][2] += tweets_df.iloc[i]['Retweets']\n",
    "                    keywords_dict[j][3] += tweets_df.iloc[i]['Sentiment_Total']\n",
    "                else:\n",
    "                    keywords_dict[j] = [1, tweets_df.iloc[i]['Likes'], tweets_df.iloc[i]['Retweets'], tweets_df.iloc[i]['Sentiment_Total']]\n",
    "\n",
    "\n",
    "for key in keywords_dict:\n",
    "    keywords_dict[key][1] = int(keywords_dict[key][1] / keywords_dict[key][0])\n",
    "    keywords_dict[key][2] = int(keywords_dict[key][2] / keywords_dict[key][0])\n",
    "    keywords_dict[key][3] = keywords_dict[key][3] / keywords_dict[key][0]\n",
    "\n",
    "keywords_df = pd.DataFrame.from_dict(keywords_dict, orient='index')\n",
    "keywords_df.columns = ['Frequency', 'Avg. Likes', 'Avg. Retweets', 'Avg. Sentiment']\n",
    "keywords_df.index.name = 'Keywords'\n",
    "keywords_df.reset_index(inplace = True)\n",
    "keywords_df = keywords_df.sort_values(['Frequency'], ascending = [False], na_position = 'last')\n",
    "keywords_df = keywords_df[:30]\n",
    "\n",
<<<<<<< HEAD
    "keywords_df\n",
    "\n"
=======
    "keywords_df\n"
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Proposed method for keyword extraction:\n",
    "\n",
    "1. Tokenize each word with part of speech tag. keep only proper nouns, nouns, adjectives, and verbs.\n",
    "2. Score the nouns and proper nouns based on amount of surrounding adjectives and verbs (using more description tends to indicate importance).\n",
    "3. Record frequency of each word; only keep words that occur above a certain number of times (frequency threshold). These will be our \"keywords\".\n",
    "4. Put the list of keywords for each tweet into the 'Keywords' column of the dataframe.\n",
    "\n",
    "Ideas for graphing the keywords/frequency/likes/retweets relationships:\n",
    "\n",
    "1. y-axis: frequency, x-axis: keyword; simple bar graph of the top keywords\n",
    "\n",
    "2. y-axis: likes/retweet count, x-axis: frequencies of keywords; scatter plot with each dot representing a keyword.\n",
    "\n",
    "3. Simple pie chart to analyze the main content areas that said Twitter account comments on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
=======
   "execution_count": 22,
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
<<<<<<< HEAD
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hoverinfo": "label+percent+name",
         "labels": [
          "america",
          "fake",
          "pensacola",
          "cnn",
          "florida",
          "market",
          "economy",
          "whitehouse",
          "alabama",
          "cuts"
         ],
         "type": "pie",
         "values": [
          10,
          9,
          8,
          7,
          6,
          6,
          4,
          4,
          4,
          4
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 600,
        "title": "User's Most Covered Topics",
        "width": 600
       }
      },
      "text/html": [
       "<div id=\"62278bed-3953-4001-854f-e5655e6cd733\" style=\"height: 600px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"62278bed-3953-4001-854f-e5655e6cd733\", [{\"type\": \"pie\", \"labels\": [\"america\", \"fake\", \"pensacola\", \"cnn\", \"florida\", \"market\", \"economy\", \"whitehouse\", \"alabama\", \"cuts\"], \"values\": [10, 9, 8, 7, 6, 6, 4, 4, 4, 4], \"hoverinfo\": \"label+percent+name\"}], {\"height\": 600, \"width\": 600, \"autosize\": false, \"title\": \"User's Most Covered Topics\"}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"62278bed-3953-4001-854f-e5655e6cd733\" style=\"height: 600px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"62278bed-3953-4001-854f-e5655e6cd733\", [{\"type\": \"pie\", \"labels\": [\"america\", \"fake\", \"pensacola\", \"cnn\", \"florida\", \"market\", \"economy\", \"whitehouse\", \"alabama\", \"cuts\"], \"values\": [10, 9, 8, 7, 6, 6, 4, 4, 4, 4], \"hoverinfo\": \"label+percent+name\"}], {\"height\": 600, \"width\": 600, \"autosize\": false, \"title\": \"User's Most Covered Topics\"}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "\n",
    "labels = keywords_df['Keywords'][0:10]\n",
    "values = keywords_df['Frequency'][0:10]\n",
    "traces = []\n",
    "\n",
    "trace = go.Pie(labels = labels, values = values, hoverinfo = 'label+percent+name')\n",
    "traces.append(trace)\n",
    "\n",
    "layout = go.Layout(height = 600,\n",
    "                   width = 600,\n",
    "                   autosize = False,\n",
    "                   title = \"User's Most Covered Topics\")\n",
    "fig = go.Figure(data = traces, layout = layout)\n",
    "py.iplot(fig, show_link = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~1mihirpandya/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~1mihirpandya/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('1mihirpandya', 'CN0KZbwKVr0a5wKrTebB')\n",
    "data = [go.Bar(\n",
    "            x=keywords_df['Keywords'],\n",
    "            y=keywords_df['Frequency']\n",
    "    )]\n",
    "\n",
    "py.iplot(data, filename='basic-bar')"
=======
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Avg. Likes</th>\n",
       "      <th>Avg. Retweets</th>\n",
       "      <th>Avg. Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>great</td>\n",
       "      <td>17</td>\n",
       "      <td>74703</td>\n",
       "      <td>15554</td>\n",
       "      <td>0.632480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>15</td>\n",
       "      <td>78736</td>\n",
       "      <td>19699</td>\n",
       "      <td>0.631233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>12</td>\n",
       "      <td>90802</td>\n",
       "      <td>23741</td>\n",
       "      <td>0.609117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pensacola</td>\n",
       "      <td>9</td>\n",
       "      <td>62174</td>\n",
       "      <td>13955</td>\n",
       "      <td>0.372297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>cuts</td>\n",
       "      <td>9</td>\n",
       "      <td>72743</td>\n",
       "      <td>16917</td>\n",
       "      <td>0.517917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tax</td>\n",
       "      <td>9</td>\n",
       "      <td>61146</td>\n",
       "      <td>15099</td>\n",
       "      <td>0.470904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>cnn</td>\n",
       "      <td>7</td>\n",
       "      <td>113415</td>\n",
       "      <td>29240</td>\n",
       "      <td>0.537169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>news</td>\n",
       "      <td>7</td>\n",
       "      <td>99604</td>\n",
       "      <td>26351</td>\n",
       "      <td>0.581112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>market</td>\n",
       "      <td>7</td>\n",
       "      <td>97657</td>\n",
       "      <td>21830</td>\n",
       "      <td>0.517571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bill</td>\n",
       "      <td>6</td>\n",
       "      <td>83169</td>\n",
       "      <td>18629</td>\n",
       "      <td>0.701984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>thank</td>\n",
       "      <td>6</td>\n",
       "      <td>73191</td>\n",
       "      <td>16846</td>\n",
       "      <td>0.600126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>florida</td>\n",
       "      <td>6</td>\n",
       "      <td>67995</td>\n",
       "      <td>15641</td>\n",
       "      <td>0.390126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honor</td>\n",
       "      <td>5</td>\n",
       "      <td>69525</td>\n",
       "      <td>16092</td>\n",
       "      <td>0.596250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>foxandfriends</td>\n",
       "      <td>5</td>\n",
       "      <td>61919</td>\n",
       "      <td>15182</td>\n",
       "      <td>0.360155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>american</td>\n",
       "      <td>5</td>\n",
       "      <td>68508</td>\n",
       "      <td>17190</td>\n",
       "      <td>0.349571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>pearl</td>\n",
       "      <td>5</td>\n",
       "      <td>72422</td>\n",
       "      <td>16416</td>\n",
       "      <td>0.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>big</td>\n",
       "      <td>5</td>\n",
       "      <td>83734</td>\n",
       "      <td>20066</td>\n",
       "      <td>0.498389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>82951</td>\n",
       "      <td>20428</td>\n",
       "      <td>0.586250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>jones</td>\n",
       "      <td>5</td>\n",
       "      <td>75417</td>\n",
       "      <td>18827</td>\n",
       "      <td>0.493016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>vote</td>\n",
       "      <td>5</td>\n",
       "      <td>71434</td>\n",
       "      <td>16798</td>\n",
       "      <td>0.514556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>christmas</td>\n",
       "      <td>5</td>\n",
       "      <td>93574</td>\n",
       "      <td>25430</td>\n",
       "      <td>0.601643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>rate</td>\n",
       "      <td>4</td>\n",
       "      <td>61867</td>\n",
       "      <td>17064</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>whitehouse</td>\n",
       "      <td>4</td>\n",
       "      <td>48774</td>\n",
       "      <td>11074</td>\n",
       "      <td>0.440833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>brian</td>\n",
       "      <td>4</td>\n",
       "      <td>93371</td>\n",
       "      <td>24663</td>\n",
       "      <td>0.527825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>you</td>\n",
       "      <td>4</td>\n",
       "      <td>69714</td>\n",
       "      <td>15348</td>\n",
       "      <td>0.512986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>clinton</td>\n",
       "      <td>4</td>\n",
       "      <td>120192</td>\n",
       "      <td>34574</td>\n",
       "      <td>0.308654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Country</td>\n",
       "      <td>4</td>\n",
       "      <td>102809</td>\n",
       "      <td>27427</td>\n",
       "      <td>0.542882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>god</td>\n",
       "      <td>4</td>\n",
       "      <td>94805</td>\n",
       "      <td>27047</td>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>abc</td>\n",
       "      <td>4</td>\n",
       "      <td>110789</td>\n",
       "      <td>31512</td>\n",
       "      <td>0.523785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>economy</td>\n",
       "      <td>4</td>\n",
       "      <td>61664</td>\n",
       "      <td>14697</td>\n",
       "      <td>0.294523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keywords  Frequency  Avg. Likes  Avg. Retweets  Avg. Sentiment\n",
       "25           great         17       74703          15554        0.632480\n",
       "4          america         15       78736          19699        0.631233\n",
       "2             fake         12       90802          23741        0.609117\n",
       "35       pensacola          9       62174          13955        0.372297\n",
       "209           cuts          9       72743          16917        0.517917\n",
       "208            tax          9       61146          15099        0.470904\n",
       "65             cnn          7      113415          29240        0.537169\n",
       "17            news          7       99604          26351        0.581112\n",
       "11          market          7       97657          21830        0.517571\n",
       "6             bill          6       83169          18629        0.701984\n",
       "52           thank          6       73191          16846        0.600126\n",
       "94         florida          6       67995          15641        0.390126\n",
       "56           honor          5       69525          16092        0.596250\n",
       "169  foxandfriends          5       61919          15182        0.360155\n",
       "153       american          5       68508          17190        0.349571\n",
       "148          pearl          5       72422          16416        0.502500\n",
       "81             big          5       83734          20066        0.498389\n",
       "59         history          5       82951          20428        0.586250\n",
       "86           jones          5       75417          18827        0.493016\n",
       "91            vote          5       71434          16798        0.514556\n",
       "103      christmas          5       93574          25430        0.601643\n",
       "114           rate          4       61867          17064        0.275000\n",
       "139     whitehouse          4       48774          11074        0.440833\n",
       "75           brian          4       93371          24663        0.527825\n",
       "53             you          4       69714          15348        0.512986\n",
       "218        clinton          4      120192          34574        0.308654\n",
       "92         Country          4      102809          27427        0.542882\n",
       "99             god          4       94805          27047        0.706250\n",
       "77             abc          4      110789          31512        0.523785\n",
       "18         economy          4       61664          14697        0.294523"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "username = 'realDonaldTrump' # working example: Donald Trump\n",
    "\n",
    "auth = tweepy.OAuthHandler('1X5fCqPl7yVvYxQjQJwkvavFD', 'NXbTDPP3HxlXOL5dWdCegEP09odLAkxUWlyRvZqXxtAtdX597G')\n",
    "auth.set_access_token('925495606931546112-mn3Hda41LsZhbYAKJtddL7TulRKucuj', 'lvCFqSLv5YvOGzCINH6JZ5cBI1CEkPKrRioBn5Iuec3Tt')\n",
    "api = tweepy.API(auth)\n",
    "    \n",
    "tweets_df = pd.DataFrame({\n",
    "    'Timestamp': (),\n",
    "    'Likes': (),\n",
    "    'Retweets': (),\n",
    "    'Text': (),\n",
    "    'Sentences': (),\n",
    "    'Sentiment_Total': (),\n",
    "    'Keywords': ()\n",
    "})\n",
    "\n",
    "tweets_df = tweets_df[['Timestamp', 'Likes', 'Retweets', 'Text', 'Sentences', 'Sentiment_Total', 'Keywords']]\n",
    "    \n",
    "recent_tweets = api.user_timeline(screen_name = username, count=100, tweet_mode=\"extended\") # analyzing 100 tweets\n",
    "for status in recent_tweets:\n",
    "    test = status.full_text\n",
    "    if test[:2] != 'RT': # removing retweets made by the user\n",
    "        status_data = pd.Series([status.created_at, status.favorite_count, status.retweet_count, status.full_text], \n",
    "                                index=['Timestamp', 'Likes', 'Retweets', 'Text'])\n",
    "    tweets_df = tweets_df.append(status_data, ignore_index = True)\n",
    "    \n",
    "tweets_df = tweets_df.drop_duplicates(subset='Text') # just in case, remove any duplicate tweets\n",
    "tweets_df = tweets_df.astype('object')\n",
    "\n",
    "keywords_dict = {}\n",
    "\n",
    "for i in range(len(tweets_df)):\n",
    "    content = tweets_df.iloc[i]['Text']\n",
    "    if 'http' in content:\n",
    "        j = content.index('http')\n",
    "        content = content[:j] # cleaning text of the tweet by removing the link at the end and newline characters\n",
    "    content = content.replace('\\n', '')\n",
    "    tweets_df.iloc[i]['Text'] = content\n",
    "    \n",
    "    blob = TextBlob(content)\n",
    "    tweets_df.iloc[i]['Sentiment_Total'] = blob.sentiment.subjectivity\n",
    "    sentiments = {}\n",
    "    \n",
    "    for sent in blob.sentences: # generating sentiment polarity values for each sentence in the tweet\n",
    "        sentiments[str(sent)] = sent.sentiment.subjectivity\n",
    "        \n",
    "    tweets_df.iloc[i]['Sentences'] = sentiments # insert dictionary of sentence: sentiment value into dataframe\n",
    "    \n",
    "    tweets_df.iloc[i]['Timestamp'] = tweets_df.iloc[i]['Timestamp'].to_pydatetime() # convert pandas.tslib.Timestamp object to datetime\n",
    "    \n",
    "    # Keyword extraction goes here\n",
    "    filtered_words = blob.noun_phrases\n",
    "#     print(filtered_words)\n",
    "    temp = []\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for x in range(len(filtered_words)):\n",
    "#             print(filtered_words[x])\n",
    "#             print(element)\n",
    "            if element != filtered_words[x] and element in filtered_words[x]:\n",
    "                temp.append(element)\n",
    "                #filtered_words = [x for x in filtered_words if x != element]\n",
    "    parts_of_speech = blob.tags\n",
    "    for element in temp:\n",
    "        filtered_words = [x for x in filtered_words if x != element]\n",
    "    \n",
    "    for x in range(len(parts_of_speech)):\n",
    "        if (parts_of_speech[x])[1] == 'NN':\n",
    "            enter = True\n",
    "            for element in filtered_words:\n",
    "                if (parts_of_speech[x])[0] in element:\n",
    "                    enter = False\n",
    "            if enter:\n",
    "                if x > 0 and (parts_of_speech[x - 1])[1] == 'PRP$':\n",
    "                    filtered_words.append((parts_of_speech[x])[0])\n",
    "    parenthesis = []\n",
    "    paren_init = 0\n",
    "    loc_begin = blob.find(\"(\", paren_init)\n",
    "    loc_end = blob.find(\")\", paren_init)\n",
    "    \n",
    "    while loc_end >= 0:\n",
    "        parenthesis.append(blob[loc_begin:loc_end])\n",
    "        paren_init = loc_end + 1\n",
    "        loc_begin = blob.find(\"(\", paren_init)\n",
    "        loc_end = blob.find(\")\", paren_init)\n",
    "    #print(parenthesis)\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for pelement in parenthesis:\n",
    "            if element in pelement.lower():\n",
    "                filtered_words = [x for x in filtered_words if x != element]\n",
    "#     tweets_df.iloc[i]['Keywords'] = filtered_words\n",
    "\n",
    "    for word in filtered_words:\n",
    "        separated = TextBlob(word).words\n",
    "        for j in separated:\n",
    "            j = j.strip()\n",
    "            if j.isalpha() and len(j) > 2:\n",
    "                if j in keywords_dict:\n",
    "                    keywords_dict[j][0] += 1\n",
    "                    keywords_dict[j][1] += tweets_df.iloc[i]['Likes']\n",
    "                    keywords_dict[j][2] += tweets_df.iloc[i]['Retweets']\n",
    "                    keywords_dict[j][3] += tweets_df.iloc[i]['Sentiment_Total']\n",
    "#                     sentiment_sum = 0\n",
    "#                     for sent in tweets_df.iloc[i]['Sentences']:\n",
    "#                         if j in sent:\n",
    "#                             sentiment_sum += tweets_df.iloc[i]['Sentences'][sent]\n",
    "#                     keywords_dict[j][3] += sentiment_sum\n",
    "                else:\n",
    "                    keywords_dict[j] = [1, tweets_df.iloc[i]['Likes'], tweets_df.iloc[i]['Retweets'], tweets_df.iloc[i]['Sentiment_Total']]\n",
    "#                     sentiment_sum = 0\n",
    "#                     for sent in tweets_df.iloc[i]['Sentences']:\n",
    "#                         if j in sent:\n",
    "#                             sentiment_sum += tweets_df.iloc[i]['Sentences'][sent]\n",
    "#                     keywords_dict[j][3] = sentiment_sum\n",
    "\n",
    "for key in keywords_dict:\n",
    "    keywords_dict[key][1] = int(keywords_dict[key][1] / keywords_dict[key][0])\n",
    "    keywords_dict[key][2] = int(keywords_dict[key][2] / keywords_dict[key][0])\n",
    "    keywords_dict[key][3] = keywords_dict[key][3] / keywords_dict[key][0]\n",
    "\n",
    "keywords_df = pd.DataFrame.from_dict(keywords_dict, orient='index')\n",
    "keywords_df.columns = ['Frequency', 'Avg. Likes', 'Avg. Retweets', 'Avg. Sentiment']\n",
    "keywords_df.index.name = 'Keywords'\n",
    "keywords_df.reset_index(inplace = True)\n",
    "keywords_df = keywords_df.sort_values(['Frequency'], ascending = [False], na_position = 'last')\n",
    "keywords_df = keywords_df[:30]\n",
    "\n",
    "keywords_df"
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~1mihirpandya/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    name = keywords_df['Keywords'],\n",
    "    x = keywords_df['Frequency'],\n",
    "    y = keywords_df['Avg. Retweets'],\n",
    "    mode = 'markers',\n",
    "    #hoverinfo = 'name'\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "py.iplot(data, filename='basic-scatter')"
   ]
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
>>>>>>> 08af33c7a71227a8a9fea8002b3190dc5adf9eb0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======

>>>>>>> 91211aafdd56f418644a9874c17b5c4e4d344466
