{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook For ReadMyMind, A CS 125 @ Illinois MP7 Project by Isaac Park and Mihir Pandya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "username = 'realDonaldTrump' # working example: Donald Trump\n",
    "\n",
    "auth = tweepy.OAuthHandler('1X5fCqPl7yVvYxQjQJwkvavFD', 'NXbTDPP3HxlXOL5dWdCegEP09odLAkxUWlyRvZqXxtAtdX597G')\n",
    "auth.set_access_token('925495606931546112-mn3Hda41LsZhbYAKJtddL7TulRKucuj', 'lvCFqSLv5YvOGzCINH6JZ5cBI1CEkPKrRioBn5Iuec3Tt')\n",
    "api = tweepy.API(auth)\n",
    "    \n",
    "tweets_df = pd.DataFrame({\n",
    "    'Timestamp': (),\n",
    "    'Likes': (),\n",
    "    'Retweets': (),\n",
    "    'Text': (),\n",
    "    'Sentences': (),\n",
    "    'Sentiment_Total': (),\n",
    "    'Keywords': ()\n",
    "})\n",
    "\n",
    "tweets_df = tweets_df[['Timestamp', 'Likes', 'Retweets', 'Text', 'Sentences', 'Sentiment_Total', 'Keywords']]\n",
    "    \n",
    "recent_tweets = api.user_timeline(screen_name = username, count=100, tweet_mode=\"extended\") # analyzing 100 tweets\n",
    "for status in recent_tweets:\n",
    "    test = status.full_text\n",
    "    if test[:2] != 'RT': # removing retweets made by the user\n",
    "        status_data = pd.Series([status.created_at, status.favorite_count, status.retweet_count, status.full_text], \n",
    "                                index=['Timestamp', 'Likes', 'Retweets', 'Text'])\n",
    "    tweets_df = tweets_df.append(status_data, ignore_index = True)\n",
    "    \n",
    "tweets_df = tweets_df.drop_duplicates(subset='Text') # just in case, remove any duplicate tweets\n",
    "tweets_df = tweets_df.astype('object')\n",
    "\n",
    "keywords_dict = {}\n",
    "\n",
    "for i in range(len(tweets_df)):\n",
    "    content = tweets_df.iloc[i]['Text']\n",
    "    if 'http' in content:\n",
    "        j = content.index('http')\n",
    "        content = content[:j] # cleaning text of the tweet by removing the link at the end and newline characters\n",
    "    content = content.replace('\\n', '')\n",
    "    tweets_df.iloc[i]['Text'] = content\n",
    "    \n",
    "    blob = TextBlob(content)\n",
    "    tweets_df.iloc[i]['Sentiment_Total'] = blob.sentiment.subjectivity\n",
    "    sentiments = {}\n",
    "    \n",
    "    for sent in blob.sentences: # generating sentiment polarity values for each sentence in the tweet\n",
    "        sentiments[str(sent)] = sent.sentiment.subjectivity\n",
    "        \n",
    "    tweets_df.iloc[i]['Sentences'] = sentiments # insert dictionary of sentence: sentiment value into dataframe\n",
    "    \n",
    "    tweets_df.iloc[i]['Timestamp'] = tweets_df.iloc[i]['Timestamp'].to_pydatetime() # convert pandas.tslib.Timestamp object to datetime\n",
    "    \n",
    "    # Keyword extraction goes here\n",
    "    filtered_words = blob.noun_phrases\n",
    "    temp = []\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for x in range(len(filtered_words)):\n",
    "            if element != filtered_words[x] and element in filtered_words[x]:\n",
    "                temp.append(element)\n",
    "    parts_of_speech = blob.tags\n",
    "    for element in temp:\n",
    "        filtered_words = [x for x in filtered_words if x != element]\n",
    "    \n",
    "    for x in range(len(parts_of_speech)):\n",
    "        if (parts_of_speech[x])[1] == 'NN':\n",
    "            enter = True\n",
    "            for element in filtered_words:\n",
    "                if (parts_of_speech[x])[0] in element:\n",
    "                    enter = False\n",
    "            if enter:\n",
    "                if x > 0 and (parts_of_speech[x - 1])[1] == 'PRP$':\n",
    "                    filtered_words.append((parts_of_speech[x])[0])\n",
    "    parenthesis = []\n",
    "    paren_init = 0\n",
    "    loc_begin = blob.find(\"(\", paren_init)\n",
    "    loc_end = blob.find(\")\", paren_init)\n",
    "    \n",
    "    while loc_end >= 0:\n",
    "        parenthesis.append(blob[loc_begin:loc_end])\n",
    "        paren_init = loc_end + 1\n",
    "        loc_begin = blob.find(\"(\", paren_init)\n",
    "        loc_end = blob.find(\")\", paren_init)\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for pelement in parenthesis:\n",
    "            if element in pelement.lower():\n",
    "                filtered_words = [x for x in filtered_words if x != element]        \n",
    "    \n",
    "    for word in filtered_words:\n",
    "        separated = TextBlob(word).words\n",
    "        for j in separated:\n",
    "            j = word.strip()\n",
    "            tb = ((TextBlob(j).tags)[0])[1]\n",
    "            if j.isalpha() and len(j) > 2 and (tb == 'NN' or tb == 'NNS' or tb == 'VBP'):\n",
    "                if j in keywords_dict:\n",
    "                    keywords_dict[j][0] += 1\n",
    "                    keywords_dict[j][1] += tweets_df.iloc[i]['Likes']\n",
    "                    keywords_dict[j][2] += tweets_df.iloc[i]['Retweets']\n",
    "                    keywords_dict[j][3] += tweets_df.iloc[i]['Sentiment_Total']\n",
    "                else:\n",
    "                    keywords_dict[j] = [1, tweets_df.iloc[i]['Likes'], tweets_df.iloc[i]['Retweets'], tweets_df.iloc[i]['Sentiment_Total']]\n",
    "\n",
    "\n",
    "for key in keywords_dict:\n",
    "    keywords_dict[key][1] = int(keywords_dict[key][1] / keywords_dict[key][0])\n",
    "    keywords_dict[key][2] = int(keywords_dict[key][2] / keywords_dict[key][0])\n",
    "    keywords_dict[key][3] = keywords_dict[key][3] / keywords_dict[key][0]\n",
    "\n",
    "keywords_df = pd.DataFrame.from_dict(keywords_dict, orient='index')\n",
    "keywords_df.columns = ['Frequency', 'Avg. Likes', 'Avg. Retweets', 'Avg. Sentiment']\n",
    "keywords_df.index.name = 'Keywords'\n",
    "keywords_df.reset_index(inplace = True)\n",
    "keywords_df = keywords_df.sort_values(['Frequency'], ascending = [False], na_position = 'last')\n",
    "keywords_df = keywords_df[:30]\n",
    "\n",
    "keywords_df\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "\n",
    "labels = keywords_df['Keywords'][0:10]\n",
    "values = keywords_df['Frequency'][0:10]\n",
    "#values = keywords_df.iloc[:,1]\n",
    "traces = []\n",
    "\n",
    "trace = go.Pie(labels = labels, values = values, hoverinfo = 'label+percent+name')\n",
    "traces.append(trace)\n",
    "\n",
    "layout = go.Layout(height = 600,\n",
    "                   width = 600,\n",
    "                   autosize = False,\n",
    "                   title = \"User's Most Covered Topics\")\n",
    "fig = go.Figure(data = traces, layout = layout)\n",
    "py.iplot(fig, show_link = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Proposed method for keyword extraction:\n",
    "\n",
    "1. Tokenize each word with part of speech tag. keep only proper nouns, nouns, adjectives, and verbs.\n",
    "2. Score the nouns and proper nouns based on amount of surrounding adjectives and verbs (using more description tends to indicate importance).\n",
    "3. Record frequency of each word; only keep words that occur above a certain number of times (frequency threshold). These will be our \"keywords\".\n",
    "4. Put the list of keywords for each tweet into the 'Keywords' column of the dataframe.\n",
    "\n",
    "Ideas for graphing the keywords/frequency/likes/retweets relationships:\n",
    "\n",
    "1. y-axis: frequency, x-axis: keyword; simple bar graph of the top keywords\n",
    "\n",
    "2. y-axis: likes/retweet count, x-axis: frequencies of keywords; scatter plot with each dot representing a keyword.\n",
    "\n",
    "3. Simple pie chart to analyze the main content areas that said Twitter account comments on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Avg. Likes</th>\n",
       "      <th>Avg. Retweets</th>\n",
       "      <th>Avg. Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>great</td>\n",
       "      <td>17</td>\n",
       "      <td>74723</td>\n",
       "      <td>15558</td>\n",
       "      <td>0.632480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>15</td>\n",
       "      <td>78806</td>\n",
       "      <td>19719</td>\n",
       "      <td>0.631233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>12</td>\n",
       "      <td>90942</td>\n",
       "      <td>23782</td>\n",
       "      <td>0.609117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pensacola</td>\n",
       "      <td>9</td>\n",
       "      <td>62208</td>\n",
       "      <td>13964</td>\n",
       "      <td>0.372297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>cuts</td>\n",
       "      <td>9</td>\n",
       "      <td>72744</td>\n",
       "      <td>16917</td>\n",
       "      <td>0.517917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tax</td>\n",
       "      <td>9</td>\n",
       "      <td>61147</td>\n",
       "      <td>15099</td>\n",
       "      <td>0.470904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>cnn</td>\n",
       "      <td>7</td>\n",
       "      <td>113492</td>\n",
       "      <td>29262</td>\n",
       "      <td>0.537169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>news</td>\n",
       "      <td>7</td>\n",
       "      <td>99728</td>\n",
       "      <td>26386</td>\n",
       "      <td>0.581112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>market</td>\n",
       "      <td>7</td>\n",
       "      <td>97721</td>\n",
       "      <td>21846</td>\n",
       "      <td>0.517571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bill</td>\n",
       "      <td>6</td>\n",
       "      <td>83228</td>\n",
       "      <td>18640</td>\n",
       "      <td>0.701984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>thank</td>\n",
       "      <td>6</td>\n",
       "      <td>73214</td>\n",
       "      <td>16853</td>\n",
       "      <td>0.600126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>florida</td>\n",
       "      <td>6</td>\n",
       "      <td>68017</td>\n",
       "      <td>15647</td>\n",
       "      <td>0.390126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honor</td>\n",
       "      <td>5</td>\n",
       "      <td>69543</td>\n",
       "      <td>16096</td>\n",
       "      <td>0.596250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>foxandfriends</td>\n",
       "      <td>5</td>\n",
       "      <td>61922</td>\n",
       "      <td>15182</td>\n",
       "      <td>0.360155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>american</td>\n",
       "      <td>5</td>\n",
       "      <td>68512</td>\n",
       "      <td>17190</td>\n",
       "      <td>0.349571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>pearl</td>\n",
       "      <td>5</td>\n",
       "      <td>72433</td>\n",
       "      <td>16417</td>\n",
       "      <td>0.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>big</td>\n",
       "      <td>5</td>\n",
       "      <td>83747</td>\n",
       "      <td>20069</td>\n",
       "      <td>0.498389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>82971</td>\n",
       "      <td>20432</td>\n",
       "      <td>0.586250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>jones</td>\n",
       "      <td>5</td>\n",
       "      <td>75438</td>\n",
       "      <td>18834</td>\n",
       "      <td>0.493016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>vote</td>\n",
       "      <td>5</td>\n",
       "      <td>71448</td>\n",
       "      <td>16802</td>\n",
       "      <td>0.514556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>christmas</td>\n",
       "      <td>5</td>\n",
       "      <td>93582</td>\n",
       "      <td>25433</td>\n",
       "      <td>0.601643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>rate</td>\n",
       "      <td>4</td>\n",
       "      <td>61883</td>\n",
       "      <td>17069</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>whitehouse</td>\n",
       "      <td>4</td>\n",
       "      <td>48783</td>\n",
       "      <td>11075</td>\n",
       "      <td>0.440833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>brian</td>\n",
       "      <td>4</td>\n",
       "      <td>93387</td>\n",
       "      <td>24667</td>\n",
       "      <td>0.527825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>you</td>\n",
       "      <td>4</td>\n",
       "      <td>69739</td>\n",
       "      <td>15355</td>\n",
       "      <td>0.512986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>clinton</td>\n",
       "      <td>4</td>\n",
       "      <td>120195</td>\n",
       "      <td>34573</td>\n",
       "      <td>0.308654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Country</td>\n",
       "      <td>4</td>\n",
       "      <td>102819</td>\n",
       "      <td>27430</td>\n",
       "      <td>0.542882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>god</td>\n",
       "      <td>4</td>\n",
       "      <td>94827</td>\n",
       "      <td>27053</td>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>abc</td>\n",
       "      <td>4</td>\n",
       "      <td>110805</td>\n",
       "      <td>31516</td>\n",
       "      <td>0.523785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>economy</td>\n",
       "      <td>4</td>\n",
       "      <td>61773</td>\n",
       "      <td>14724</td>\n",
       "      <td>0.294523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keywords  Frequency  Avg. Likes  Avg. Retweets  Avg. Sentiment\n",
       "25           great         17       74723          15558        0.632480\n",
       "4          america         15       78806          19719        0.631233\n",
       "2             fake         12       90942          23782        0.609117\n",
       "35       pensacola          9       62208          13964        0.372297\n",
       "209           cuts          9       72744          16917        0.517917\n",
       "208            tax          9       61147          15099        0.470904\n",
       "65             cnn          7      113492          29262        0.537169\n",
       "17            news          7       99728          26386        0.581112\n",
       "11          market          7       97721          21846        0.517571\n",
       "6             bill          6       83228          18640        0.701984\n",
       "52           thank          6       73214          16853        0.600126\n",
       "94         florida          6       68017          15647        0.390126\n",
       "56           honor          5       69543          16096        0.596250\n",
       "169  foxandfriends          5       61922          15182        0.360155\n",
       "153       american          5       68512          17190        0.349571\n",
       "148          pearl          5       72433          16417        0.502500\n",
       "81             big          5       83747          20069        0.498389\n",
       "59         history          5       82971          20432        0.586250\n",
       "86           jones          5       75438          18834        0.493016\n",
       "91            vote          5       71448          16802        0.514556\n",
       "103      christmas          5       93582          25433        0.601643\n",
       "114           rate          4       61883          17069        0.275000\n",
       "139     whitehouse          4       48783          11075        0.440833\n",
       "75           brian          4       93387          24667        0.527825\n",
       "53             you          4       69739          15355        0.512986\n",
       "218        clinton          4      120195          34573        0.308654\n",
       "92         Country          4      102819          27430        0.542882\n",
       "99             god          4       94827          27053        0.706250\n",
       "77             abc          4      110805          31516        0.523785\n",
       "18         economy          4       61773          14724        0.294523"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "username = 'realDonaldTrump' # working example: Donald Trump\n",
    "\n",
    "auth = tweepy.OAuthHandler('1X5fCqPl7yVvYxQjQJwkvavFD', 'NXbTDPP3HxlXOL5dWdCegEP09odLAkxUWlyRvZqXxtAtdX597G')\n",
    "auth.set_access_token('925495606931546112-mn3Hda41LsZhbYAKJtddL7TulRKucuj', 'lvCFqSLv5YvOGzCINH6JZ5cBI1CEkPKrRioBn5Iuec3Tt')\n",
    "api = tweepy.API(auth)\n",
    "    \n",
    "tweets_df = pd.DataFrame({\n",
    "    'Timestamp': (),\n",
    "    'Likes': (),\n",
    "    'Retweets': (),\n",
    "    'Text': (),\n",
    "    'Sentences': (),\n",
    "    'Sentiment_Total': (),\n",
    "    'Keywords': ()\n",
    "})\n",
    "\n",
    "tweets_df = tweets_df[['Timestamp', 'Likes', 'Retweets', 'Text', 'Sentences', 'Sentiment_Total', 'Keywords']]\n",
    "    \n",
    "recent_tweets = api.user_timeline(screen_name = username, count=100, tweet_mode=\"extended\") # analyzing 100 tweets\n",
    "for status in recent_tweets:\n",
    "    test = status.full_text\n",
    "    if test[:2] != 'RT': # removing retweets made by the user\n",
    "        status_data = pd.Series([status.created_at, status.favorite_count, status.retweet_count, status.full_text], \n",
    "                                index=['Timestamp', 'Likes', 'Retweets', 'Text'])\n",
    "    tweets_df = tweets_df.append(status_data, ignore_index = True)\n",
    "    \n",
    "tweets_df = tweets_df.drop_duplicates(subset='Text') # just in case, remove any duplicate tweets\n",
    "tweets_df = tweets_df.astype('object')\n",
    "\n",
    "keywords_dict = {}\n",
    "\n",
    "for i in range(len(tweets_df)):\n",
    "    content = tweets_df.iloc[i]['Text']\n",
    "    if 'http' in content:\n",
    "        j = content.index('http')\n",
    "        content = content[:j] # cleaning text of the tweet by removing the link at the end and newline characters\n",
    "    content = content.replace('\\n', '')\n",
    "    tweets_df.iloc[i]['Text'] = content\n",
    "    \n",
    "    blob = TextBlob(content)\n",
    "    tweets_df.iloc[i]['Sentiment_Total'] = blob.sentiment.subjectivity\n",
    "    sentiments = {}\n",
    "    \n",
    "    for sent in blob.sentences: # generating sentiment polarity values for each sentence in the tweet\n",
    "        sentiments[str(sent)] = sent.sentiment.subjectivity\n",
    "        \n",
    "    tweets_df.iloc[i]['Sentences'] = sentiments # insert dictionary of sentence: sentiment value into dataframe\n",
    "    \n",
    "    tweets_df.iloc[i]['Timestamp'] = tweets_df.iloc[i]['Timestamp'].to_pydatetime() # convert pandas.tslib.Timestamp object to datetime\n",
    "    \n",
    "    # Keyword extraction goes here\n",
    "    filtered_words = blob.noun_phrases\n",
    "#     print(filtered_words)\n",
    "    temp = []\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for x in range(len(filtered_words)):\n",
    "#             print(filtered_words[x])\n",
    "#             print(element)\n",
    "            if element != filtered_words[x] and element in filtered_words[x]:\n",
    "                temp.append(element)\n",
    "                #filtered_words = [x for x in filtered_words if x != element]\n",
    "    parts_of_speech = blob.tags\n",
    "    for element in temp:\n",
    "        filtered_words = [x for x in filtered_words if x != element]\n",
    "    \n",
    "    for x in range(len(parts_of_speech)):\n",
    "        if (parts_of_speech[x])[1] == 'NN':\n",
    "            enter = True\n",
    "            for element in filtered_words:\n",
    "                if (parts_of_speech[x])[0] in element:\n",
    "                    enter = False\n",
    "            if enter:\n",
    "                if x > 0 and (parts_of_speech[x - 1])[1] == 'PRP$':\n",
    "                    filtered_words.append((parts_of_speech[x])[0])\n",
    "    parenthesis = []\n",
    "    paren_init = 0\n",
    "    loc_begin = blob.find(\"(\", paren_init)\n",
    "    loc_end = blob.find(\")\", paren_init)\n",
    "    \n",
    "    while loc_end >= 0:\n",
    "        parenthesis.append(blob[loc_begin:loc_end])\n",
    "        paren_init = loc_end + 1\n",
    "        loc_begin = blob.find(\"(\", paren_init)\n",
    "        loc_end = blob.find(\")\", paren_init)\n",
    "    #print(parenthesis)\n",
    "    \n",
    "    for element in filtered_words:\n",
    "        for pelement in parenthesis:\n",
    "            if element in pelement.lower():\n",
    "                filtered_words = [x for x in filtered_words if x != element]\n",
    "#     tweets_df.iloc[i]['Keywords'] = filtered_words\n",
    "\n",
    "    for word in filtered_words:\n",
    "        separated = TextBlob(word).words\n",
    "        for j in separated:\n",
    "            j = j.strip()\n",
    "            if j.isalpha() and len(j) > 2:\n",
    "                if j in keywords_dict:\n",
    "                    keywords_dict[j][0] += 1\n",
    "                    keywords_dict[j][1] += tweets_df.iloc[i]['Likes']\n",
    "                    keywords_dict[j][2] += tweets_df.iloc[i]['Retweets']\n",
    "                    keywords_dict[j][3] += tweets_df.iloc[i]['Sentiment_Total']\n",
    "#                     sentiment_sum = 0\n",
    "#                     for sent in tweets_df.iloc[i]['Sentences']:\n",
    "#                         if j in sent:\n",
    "#                             sentiment_sum += tweets_df.iloc[i]['Sentences'][sent]\n",
    "#                     keywords_dict[j][3] += sentiment_sum\n",
    "                else:\n",
    "                    keywords_dict[j] = [1, tweets_df.iloc[i]['Likes'], tweets_df.iloc[i]['Retweets'], tweets_df.iloc[i]['Sentiment_Total']]\n",
    "#                     sentiment_sum = 0\n",
    "#                     for sent in tweets_df.iloc[i]['Sentences']:\n",
    "#                         if j in sent:\n",
    "#                             sentiment_sum += tweets_df.iloc[i]['Sentences'][sent]\n",
    "#                     keywords_dict[j][3] = sentiment_sum\n",
    "\n",
    "for key in keywords_dict:\n",
    "    keywords_dict[key][1] = int(keywords_dict[key][1] / keywords_dict[key][0])\n",
    "    keywords_dict[key][2] = int(keywords_dict[key][2] / keywords_dict[key][0])\n",
    "    keywords_dict[key][3] = keywords_dict[key][3] / keywords_dict[key][0]\n",
    "\n",
    "keywords_df = pd.DataFrame.from_dict(keywords_dict, orient='index')\n",
    "keywords_df.columns = ['Frequency', 'Avg. Likes', 'Avg. Retweets', 'Avg. Sentiment']\n",
    "keywords_df.index.name = 'Keywords'\n",
    "keywords_df.reset_index(inplace = True)\n",
    "keywords_df = keywords_df.sort_values(['Frequency'], ascending = [False], na_position = 'last')\n",
    "keywords_df = keywords_df[:30]\n",
    "\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
